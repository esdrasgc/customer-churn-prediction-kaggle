{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1f6d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path_data = pathlib.Path().cwd().parent / 'data'\n",
    "\n",
    "dados_train = pd.read_csv(path_data / \"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29f0252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dados_train.iloc[:, :-1]\n",
    "y = dados_train.iloc[:, -1].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1901d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes treino: {0: 1755, 1: 1755} val: {0: 375, 1: 375} teste: {0: 375, 1: 375}\n",
      "[GRID] hls=(16,), act=relu, solver=adam, eta=0.001, alpha=0.0001, bs=64, patience=30, max_epochs=300, tol=0.0001, momentum=None, nest=None, lr_policy=None\n",
      "[GRID] hls=(16,), act=relu, solver=adam, eta=0.001, alpha=0.0001, bs=64, patience=30, max_epochs=500, tol=0.0001, momentum=None, nest=None, lr_policy=None\n",
      "[GRID] hls=(16,), act=relu, solver=adam, eta=0.001, alpha=0.0001, bs=64, patience=30, max_epochs=700, tol=0.0001, momentum=None, nest=None, lr_policy=None\n",
      "[GRID] hls=(16,), act=relu, solver=adam, eta=0.001, alpha=0.0001, bs=64, patience=30, max_epochs=1000, tol=0.0001, momentum=None, nest=None, lr_policy=None\n",
      "[GRID] hls=(16,), act=relu, solver=adam, eta=0.001, alpha=0.0001, bs=64, patience=50, max_epochs=300, tol=0.0001, momentum=None, nest=None, lr_policy=None\n",
      "[GRID] hls=(16,), act=relu, solver=adam, eta=0.001, alpha=0.0001, bs=64, patience=50, max_epochs=500, tol=0.0001, momentum=None, nest=None, lr_policy=None\n",
      "[GRID] hls=(16,), act=relu, solver=adam, eta=0.001, alpha=0.0001, bs=64, patience=50, max_epochs=700, tol=0.0001, momentum=None, nest=None, lr_policy=None\n",
      "[GRID] hls=(16,), act=relu, solver=adam, eta=0.001, alpha=0.0001, bs=64, patience=50, max_epochs=1000, tol=0.0001, momentum=None, nest=None, lr_policy=None\n",
      "[GRID] hls=(16,), act=relu, solver=adam, eta=0.001, alpha=0.0001, bs=64, patience=100, max_epochs=300, tol=0.0001, momentum=None, nest=None, lr_policy=None\n",
      "[GRID] hls=(16,), act=relu, solver=adam, eta=0.001, alpha=0.0001, bs=64, patience=100, max_epochs=500, tol=0.0001, momentum=None, nest=None, lr_policy=None\n",
      "[GRID] hls=(16,), act=relu, solver=adam, eta=0.001, alpha=0.0001, bs=64, patience=100, max_epochs=700, tol=0.0001, momentum=None, nest=None, lr_policy=None\n",
      "[GRID] hls=(16,), act=relu, solver=adam, eta=0.001, alpha=0.0001, bs=64, patience=100, max_epochs=1000, tol=0.0001, momentum=None, nest=None, lr_policy=None\n",
      "[GRID] hls=(16,), act=relu, solver=adam, eta=0.001, alpha=0.0001, bs=64, patience=200, max_epochs=300, tol=0.0001, momentum=None, nest=None, lr_policy=None\n",
      "[GRID] hls=(16,), act=relu, solver=adam, eta=0.001, alpha=0.0001, bs=64, patience=200, max_epochs=500, tol=0.0001, momentum=None, nest=None, lr_policy=None\n",
      "[GRID] hls=(16,), act=relu, solver=adam, eta=0.001, alpha=0.0001, bs=64, patience=200, max_epochs=700, tol=0.0001, momentum=None, nest=None, lr_policy=None\n",
      "[GRID] hls=(16,), act=relu, solver=adam, eta=0.001, alpha=0.0001, bs=64, patience=200, max_epochs=1000, tol=0.0001, momentum=None, nest=None, lr_policy=None\n"
     ]
    }
   ],
   "source": [
    "import importlib, train_mlp_cv_optuna as t\n",
    "\n",
    "t = importlib.reload(t)\n",
    "from train_mlp_cv_optuna import split_70_15_15_balanced, gridsearch_mlp, plot_history\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# suas listas\n",
    "categorical_vars = [\n",
    "    \"Gender\",\n",
    "    \"Location\",\n",
    "    \"Subscription_Type\",\n",
    "    \"Last_Interaction_Type\",\n",
    "    \"Promo_Opted_In\",\n",
    "]\n",
    "continuous_vars = [\n",
    "    \"Age\",\n",
    "    \"Account_Age_Months\",\n",
    "    \"Monthly_Spending\",\n",
    "    \"Total_Usage_Hours\",\n",
    "    \"Streaming_Usage\",\n",
    "    \"Discount_Used\",\n",
    "    \"Satisfaction_Score\",\n",
    "]\n",
    "discrete_vars = [\"Support_Calls\", \"Late_Payments\", \"Complaint_Tickets\"]\n",
    "\n",
    "# 1) Split 70/15/15 balanceado\n",
    "X_tr, X_va, X_te, y_tr, y_va, y_te = split_70_15_15_balanced(X, y, random_state=42)\n",
    "\n",
    "\n",
    "# (sanidade) paridade\n",
    "def _count(yv):\n",
    "    yv = np.asarray(yv).ravel()\n",
    "    return {0: int((yv == 0).sum()), 1: int((yv == 1).sum())}\n",
    "\n",
    "\n",
    "print(\"Classes treino:\", _count(y_tr), \"val:\", _count(y_va), \"teste:\", _count(y_te))\n",
    "\n",
    "# 2) Grid: neurônios/camadas + ativações (F1 como métrica de seleção)\n",
    "# param_grid = {\n",
    "#     \"hidden_layer_sizes\": [\n",
    "#         (16,), (32,), (64,), (128,),\n",
    "#         (32,16), (64,32), (64,64), (128,64),\n",
    "#         (128,64,32),  # 3 camadas\n",
    "#         (3,),         # seu caso minimalista\n",
    "#     ],\n",
    "#     \"activation\": [\"relu\", \"tanh\", \"logistic\"],\n",
    "# }\n",
    "param_grid = {\n",
    "    \"hidden_layer_sizes\": [\n",
    "        (16,),\n",
    "        (32,),\n",
    "        (64,),\n",
    "        (128,),\n",
    "        (32, 16),\n",
    "        (64, 32),\n",
    "        (64, 64),\n",
    "        (128, 64),\n",
    "        (128, 64, 32),  # 3 camadas\n",
    "        (3,),  # seu caso minimalista\n",
    "    ],\n",
    "    \"activation\": [\"relu\", \"tanh\", \"logistic\"],\n",
    "    \"solver\": [\"adam\", \"sgd\"],  # 'lbfgs' será pulado (sem partial_fit)\n",
    "    \"learning_rate_init\": [1e-3, 5e-4, 1e-4],  # etas\n",
    "    \"patience\": [30, 50, 100, 200],  # paciência por combinação\n",
    "    \"max_epochs\": [300, 500, 700, 1000],  # épocas máximas por combinação\n",
    "}\n",
    "\n",
    "best, trials = gridsearch_mlp(\n",
    "    X_tr,\n",
    "    y_tr,\n",
    "    X_va,\n",
    "    y_va,\n",
    "    categorical_vars=categorical_vars,\n",
    "    continuous_vars=continuous_vars,\n",
    "    discrete_vars=discrete_vars,\n",
    "    param_grid=param_grid,\n",
    "    tol=1e-4,\n",
    "    random_state=42,\n",
    "    alpha=1e-4,\n",
    "    learning_rate_init=1e-3,\n",
    "    batch_size=64,\n",
    "    monitor=\"val_f1\",  # << seleciona pelo F1\n",
    "    monitor_mode=\"max\",\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print(\"\\n== MELHOR CONFIGURAÇÃO ==\")\n",
    "print(best[\"params\"])\n",
    "print(best[\"stats\"])\n",
    "\n",
    "# 3) Plots do melhor\n",
    "plot_history(best[\"history\"])\n",
    "\n",
    "# 4) Teste (15%)\n",
    "clf = best[\"clf\"]\n",
    "X_te_t = clf.preprocess_.transform(X_te)\n",
    "y_pred = clf.predict(X_te_t)\n",
    "print(\"Acurácia (teste):\", accuracy_score(y_te, y_pred))\n",
    "print(\"F1 (teste):\", f1_score(y_te, y_pred, average=\"binary\", pos_label=1))\n",
    "try:\n",
    "    print(classification_report(y_te, y_pred, target_names=dados_train.target_names))\n",
    "except Exception:\n",
    "    print(classification_report(y_te, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312801bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Inferência no teste e exportação CSV (Customer_ID, Churn)\n",
    "import pandas as pd\n",
    "\n",
    "OUTPUT_CSV = \"test_predictions_labels.csv\"\n",
    "\n",
    "# melhor modelo do grid\n",
    "clf = best[\"clf\"]\n",
    "\n",
    "# lê o CSV de teste (mantém índice para alinhamento)\n",
    "X_teste = pd.read_csv(path_data / \"test.csv\")\n",
    "\n",
    "# (opcional) garanta que não passaremos a coluna alvo por engano\n",
    "if \"Churn\" in X_teste.columns:\n",
    "    X_teste = X_teste.drop(columns=[\"Churn\"])\n",
    "\n",
    "# transforma e prediz\n",
    "X_te_t = clf.preprocess_.transform(X_teste)          # ndarray\n",
    "y_pred = clf.predict(X_te_t)\n",
    "y_pred = pd.Series(y_pred, index=X_teste.index, name=\"Churn\").astype(int)\n",
    "\n",
    "# captura os IDs de cliente\n",
    "if \"Customer_ID\" in X_teste.columns:\n",
    "    ids = X_teste[\"Customer_ID\"]\n",
    "else:\n",
    "    # fallback: usa posição como ID\n",
    "    ids = pd.Series(range(len(y_pred)), index=y_pred.index, name=\"Customer_ID\")\n",
    "\n",
    "# monta saída e salva\n",
    "preds = pd.concat([ids.reset_index(drop=True), y_pred.reset_index(drop=True)], axis=1)\n",
    "preds.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"Arquivo salvo em: {OUTPUT_CSV}\")\n",
    "preds.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3e6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.value_counts(\"Churn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0355ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, train_mlp_cv_optuna as t\n",
    "t = importlib.reload(t)\n",
    "from train_mlp_cv_optuna import (\n",
    "    split_70_15_15_balanced,\n",
    "    gridsearch_mlp,\n",
    "    summarize_trials,\n",
    "    export_trials_history,\n",
    "    plot_history,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# suas listas\n",
    "categorical_vars = ['Gender','Location','Subscription_Type','Last_Interaction_Type','Promo_Opted_In']\n",
    "continuous_vars  = ['Age','Account_Age_Months','Monthly_Spending','Total_Usage_Hours','Streaming_Usage','Discount_Used','Satisfaction_Score']\n",
    "discrete_vars    = ['Support_Calls','Late_Payments','Complaint_Tickets']\n",
    "\n",
    "# 1) Split 70/15/15 balanceado\n",
    "X_tr, X_va, X_te, y_tr, y_va, y_te = split_70_15_15_balanced(X, y, random_state=42)\n",
    "\n",
    "# 2) Grid ampliado\n",
    "param_grid = {\n",
    "    \"hidden_layer_sizes\": [(32,), (64,), (128,), (64,32), (128,64), (128,64,32)],\n",
    "    \"activation\": [\"relu\", \"tanh\", \"logistic\"],\n",
    "    \"solver\": [\"adam\", \"sgd\"],                  # 'lbfgs' será pulado (sem partial_fit)\n",
    "    \"learning_rate_init\": [1e-3, 5e-4, 1e-4],   # etas\n",
    "    \"alpha\": [1e-4, 1e-3],\n",
    "    \"batch_size\": [64, 128],\n",
    "    \"patience\": [10, 20, 30],                   # paciência por combinação\n",
    "    \"max_epochs\": [200, 300],                   # épocas máximas por combinação\n",
    "    \"tol\": [1e-4],                              # tol do monitor\n",
    "    # extras p/ SGD:\n",
    "    \"momentum\": [0.9],\n",
    "    \"nesterovs_momentum\": [True],\n",
    "    \"learning_rate\": [\"constant\", \"adaptive\"],\n",
    "}\n",
    "\n",
    "best, trials = gridsearch_mlp(\n",
    "    X_tr, y_tr, X_va, y_va,\n",
    "    categorical_vars=categorical_vars,\n",
    "    continuous_vars=continuous_vars,\n",
    "    discrete_vars=discrete_vars,\n",
    "    param_grid=param_grid,\n",
    "    monitor=\"val_f1\",        # seleção por F1 de validação\n",
    "    monitor_mode=\"max\",\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print(\"\\n== MELHOR CONFIGURAÇÃO ==\")\n",
    "print(best[\"params\"])\n",
    "print(best[\"stats\"])\n",
    "\n",
    "# 3) Plots do melhor\n",
    "plot_history(best[\"history\"])\n",
    "\n",
    "# 4) Avaliação no teste (15%)\n",
    "clf = best[\"clf\"]\n",
    "X_te_t = clf.preprocess_.transform(X_te)\n",
    "y_pred = clf.predict(X_te_t)\n",
    "print(\"Acurácia (teste):\", accuracy_score(y_te, y_pred))\n",
    "print(\"F1 (teste):\", f1_score(y_te, y_pred, average=\"binary\", pos_label=1))\n",
    "try:\n",
    "    print(classification_report(y_te, y_pred, target_names=dados_train.target_names))\n",
    "except Exception:\n",
    "    print(classification_report(y_te, y_pred))\n",
    "\n",
    "# 5) Salvar TODOS os resultados\n",
    "summary_csv = \"grid_summary_results.csv\"\n",
    "history_csv = \"grid_history_epochs.csv\"\n",
    "\n",
    "df_summary = summarize_trials(trials, save_path=summary_csv)\n",
    "df_history = export_trials_history(trials, save_path=history_csv)\n",
    "\n",
    "print(f\"Resumo salvo em: {summary_csv} (linhas: {len(df_summary)})\")\n",
    "print(f\"Histórico por época salvo em: {history_csv} (linhas: {len(df_history)})\")\n",
    "\n",
    "# (Opcional) Top-5 por best_val_f1\n",
    "display(df_summary.sort_values(\"best_val_f1\", ascending=False).head(5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curstomer-churn (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
